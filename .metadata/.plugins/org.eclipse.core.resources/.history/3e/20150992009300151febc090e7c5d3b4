import java.io.IOException;
import java.io.OutputStream;
import java.net.ServerSocket;
import java.net.Socket;

import lejos.hardware.Button;
import lejos.hardware.Sound;
import lejos.hardware.lcd.LCD;

import org.opencv.core.Core;
import org.opencv.core.Mat;
import org.opencv.core.MatOfByte;
import org.opencv.core.MatOfRect;
import org.opencv.core.Point;
import org.opencv.core.Rect;
import org.opencv.core.Scalar;
import org.opencv.core.Size;
import org.opencv.highgui.Highgui;
import org.opencv.highgui.VideoCapture;
import org.opencv.imgproc.Imgproc;
import org.opencv.objdetect.CascadeClassifier;

/**
 * Detect a face in the video stream from the camera and highlight the face in the image
 * streamed to the web-browser
 * 
 * @author mcrosbie
 * @date 22/11/2015
 *
 */
public class FaceDetect {
	
	public static void main(String[] args) throws Exception {

		System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
		DetectFaceDemo d;
		
		if(args.length > 0) {
			int min = Integer.parseInt(args[0]);
			double scale = Float.parseFloat(args[1]);
			String features;
			if(args[2].equals("h")) {
				features = "/haarcascade_frontalface_alt.xml";
			} else {
				features = "lbpcascade_frontalface.xml"; 
			}
			
			d = new DetectFaceDemo(0, scale, min, features);
			
		} else {
			d = new DetectFaceDemo();
		}
	    d.run();
	}
}

class DetectFaceDemo {

	private int frameCount = 0;
	private CascadeClassifier faceDetector;
	
	private int flags = 0;
	private double scaleFactor = 1.5;
	private int minNeighbours = 1;
    private Size minSize = new Size(20,20);
    private Size maxSize = new Size(160,120);
    private final String HaarFeatures = "/haarcascade_frontalface_alt.xml";  //classifiers to detect eyes and face.
    private final String LbpFeatures = "/lbpcascade_frontalface.xml";
    private String features;
    
    public DetectFaceDemo() {
    	features = LbpFeatures;
    }
    
    public DetectFaceDemo(int _flags, double _scale, int _minNeighbours, String _features) {
    	flags = _flags;
    	scaleFactor = _scale;
    	minNeighbours = _minNeighbours;
    	features = _features;
    }
    
	public void run() throws Exception {
		
	    Mat frame = new Mat();
	    
        VideoCapture vid = new VideoCapture(0);
        vid.set(Highgui.CV_CAP_PROP_FRAME_WIDTH, 160);
        vid.set(Highgui.CV_CAP_PROP_FRAME_HEIGHT, 120);
        vid.open(0);
        System.out.println("Camera open");   
        
        faceDetector = new CascadeClassifier(getClass().getResource(features).getPath());

        if(faceDetector.empty()) {
        	System.err.println("Failed to load classifier ");
        	Sound.buzz();
        	System.exit(1);
        } else {
        	System.out.println("Loaded classifier");
        }

        ServerSocket ss = new ServerSocket(8080);
        Socket sock = ss.accept();
        System.out.println("Socket connected");
        String boundary = "Thats it folks!";
        writeHeader(sock.getOutputStream(), boundary);
        System.out.println("Written header");
          
        /**
         * Capture images and stream to the web client
         */
        while (Button.ESCAPE.isUp()) {
            
        	vid.read(frame);     	
        	//System.out.println("Reading file");
        	//frame = Highgui.imread(getClass().getResource("/faces/BioID_0000.pgm").getPath());
        	
            if (!frame.empty()) {
            	
            	System.out.println("Starting rescaling...");
                long startTime = System.nanoTime();  
                MatOfRect faces = new MatOfRect();
                Mat mRgba=new Mat();  
                Mat mGrey=new Mat();  
                frame.copyTo(mRgba);  
                frame.copyTo(mGrey);  
                Imgproc.cvtColor( mRgba, mGrey, Imgproc.COLOR_BGR2GRAY);  
                Imgproc.equalizeHist( mGrey, mGrey );  
                long endTime = System.nanoTime();  
                System.out.println(String.format("rescaling done: took %.2f ms", 
                		(float)(endTime - startTime)/1000000));  
                
                System.out.println("Calling detectMultiScale");
                
                // detect faces
                startTime = System.nanoTime();  
                faceDetector.detectMultiScale(
                		mGrey, 
                		faces,
                		scaleFactor,
                		minNeighbours,
                		flags,
                		minSize,
                		maxSize);
                endTime = System.nanoTime();  

                System.out.println(String.format("detectMultiScale done: took %.2f ms", 
                		(float)(endTime - startTime)/1000000));  

                LCD.drawInt(frameCount++, 0, 6);
                int numFaces = faces.toArray().length;
                if(numFaces > 0) {
                	LCD.drawString(String.format("Detected %s faces", numFaces), 0, 5);
                	System.out.println(String.format("Detected %s faces", numFaces));

		            // each rectangle in faces is a face
		            Rect[] facesArray = faces.toArray();
		            for (int i = 0; i < facesArray.length; i++) {
		            	Rect rect = facesArray[i];
		                Point center= new Point(rect.x + rect.width*0.5, rect.y + rect.height*0.5 );  
		                System.out.println("Face centre x,y="+center.x+","+center.y);
		                if(center.x < (frame.width()/2)) {
		                	System.out.println("Face to the LEFT");
		                } else {
		                	System.out.println("Face to the RIGHT");
		                }
		                
		            	Core.rectangle(frame, rect.tl(), rect.br(), new Scalar(0, 255, 0, 255), 2);
		            }
                } else {
                	LCD.clear(5);
                }

                startTime = System.nanoTime();  
                writeJpg(sock.getOutputStream(), frame, boundary);
                endTime = System.nanoTime();  

                System.out.println(String.format("sending JPG done: took %.2f ms", 
                		(float)(endTime - startTime)/1000000));  

             } else {
            	 System.out.println("No picture");
             }
        }
        sock.close();
        ss.close();    
	}
	
	/**
	 * Write the HTTP header to the output stream
	 * 
	 * @param stream OutputStream connected to the connect
	 * @param boundary Text to insert between messages
	 * @throws IOException
	 */
    private void writeHeader(OutputStream stream, String boundary) throws IOException {
        stream.write(("HTTP/1.0 200 OK\r\n" +
                "Connection: close\r\n" +
                "Max-Age: 0\r\n" +
                "Expires: 0\r\n" +
                "Cache-Control: no-store, no-cache, must-revalidate, pre-check=0, post-check=0, max-age=0\r\n" +
                "Pragma: no-cache\r\n" + 
                "Content-Type: multipart/x-mixed-replace; " +
                "boundary=" + boundary + "\r\n" +
                "\r\n" +
                "--" + boundary + "\r\n").getBytes());
    }

    /**
     * Convert an OpenCV matrix into JPG format and write it to the HTTP output stream
     * 
     * @param stream
     * @param img
     * @param boundary
     * @throws IOException
     */
    private void writeJpg(OutputStream stream, Mat img, String boundary) throws IOException {
        MatOfByte buf = new MatOfByte();
        Highgui.imencode(".jpg", img, buf);
        byte[] imageBytes = buf.toArray();
        stream.write(("Content-type: image/jpeg\r\n" +
                "Content-Length: " + imageBytes.length + "\r\n" +
                "\r\n").getBytes());
        stream.write(imageBytes);
        stream.write(("\r\n--" + boundary + "\r\n").getBytes());
    }
}
